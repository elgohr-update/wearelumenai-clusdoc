<!DOCTYPE html>
<html lang="en-us">

<head>
  <meta name="generator" content="Hugo 0.40.1" />
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Air Quality with Plumelabs  | The lady of the lake</title>

  
  <meta name="description" content="Batch analysis of Air Quality"> 
  
  
  
  
  

  

  <meta name="author" content="LumenAI">


  <meta property="og:title" content="Air Quality with Plumelabs" />
<meta property="og:description" content="Batch analysis of Air Quality" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/docs/tutorials/nlp-with-bbc-news/" />



<meta property="article:published_time" content="2019-12-19T12:32:00&#43;01:00"/>

<meta property="article:modified_time" content="2019-12-19T12:32:00&#43;01:00"/>











  




  
  
  
  
  

  <link rel="canonical" href="http://localhost:1313/docs/tutorials/nlp-with-bbc-news/">  

  <link rel="shortcut icon" type="image/png" href="data:image/png;base64,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">


  <link href="/css/font.css" rel="stylesheet" type="text/css">
  <link href="/css/kube.css" rel="stylesheet" type="text/css">
  <link href="/css/kube.legenda.css" rel="stylesheet" type="text/css">
  <link href="/css/highlight.css" rel="stylesheet" type="text/css">
  <link href="/css/master.css" rel="stylesheet" type="text/css">
  <link href="/css/kube.demo.css" rel="stylesheet" type="text/css">

  <link href="/css/fontawesome.css" rel="stylesheet" type="text/css">


 <link href="/css/custom.css" rel="stylesheet" type="text/css">

  <script src="/js/jquery-2.1.4.min.js" type="text/javascript">
  </script>

  <script type="text/javascript" src="/js/tocbot.min.js"></script>
</head>


<body class="page-kube">
  <header> <div class="show-sm">
    <div id="nav-toggle-box">
      <div id="nav-toggle-brand">
        <a href="/"><i class="fa fa-home"></i></a>
      </div><a data-component="toggleme" data-target="#top" href="#" id="nav-toggle"><i class="fa fa-home"></i></a>
    </div>
  </div>
  <div class="hide-sm" id="top">
    <div id="top-brand">
      <a href="/" title="home"><i class="fa fa-home"></i></a>
    </div>
    <nav id="top-nav-main">
      <ul>
       
       
    <li><a href="/blog/" ><i class='fas fa-rss-square'></i> Blog </a></li>
    
    <li><a href="/docs/" ><i class='fa fa-info-circle'></i> Documentation </a></li>
    
      </ul>
    </nav>
    <nav id="top-nav-extra"> 
      <ul>
          
      </ul>
    </nav>
  </div>
 </header>
  <main>
  <div id="main">
    <div id="hero">
      <h1> Air Quality with Plumelabs </h1>
      <p class="hero-lead">
           Batch analysis of Air Quality.
      </p>
    </div>

    <div class="breadcrumbs">
      
  
    
  
    
  
    
  
    <a href="/"><i class="fas fa-home"></i></a>
  
 /

    
      <a href="/docs/">Documentation</a>
    
  
 /

    
      <a href="/docs/tutorials/">Tutorials</a>
    
  
 /

    
      <a>Air Quality with Plumelabs</a>
    
  

    </div> 

    <div id="kube-component" class="content">

    
<nav id="contents">
    <ol class="js-toc">
    </ol>
</nav>
<script type="text/javascript">
document.addEventListener("DOMContentLoaded",
function(){
tocbot.init({

tocSelector: '.js-toc',

contentSelector: '.content',

headingSelector: 'h1,h2,h3,h4'
})
}
);
</script>




    

<h1 id="nlp-with-bbc-news-articles">NLP with BBC news articles</h1>

<p>In this notebook, we use distclus4py and bubbles4py to perform batch and online analysis of a dataset of 2225 BBC news articles from <a href="http://mlg.ucd.ie/datasets/bbc.html">http://mlg.ucd.ie/datasets/bbc.html</a> with 5 topics (business, entertainment, politics, sport, tech) and build a javascript visualization of the results.</p>

<p>We stack several steps as follows:</p>

<ol>
<li>Batch training of x% of the sample:

<ul>
<li>construction of a word embedding with fasttext thanks to the articles bodies,</li>
<li>clustering based on a batch analysis with one given algorithm (streaming, mcmc, or kmeans from distclus4py package).</li>
</ul></li>

<li><p>Vizualization of the result thanks to bubbles4py</p></li>

<li><p>On the fly clustering of a test set:</p>

<ul>
<li>real time embedding thanks to the fasttext embedding trained in 1.,</li>
<li>online clustering with initialisation based on 1.</li>
</ul></li>

<li><p>Vizualization of the resulting clusters to compare with 2.</p></li>
</ol>

<h2 id="data-extraction">Data extraction</h2>

<pre><code class="language-python">from os import listdir

folders = ['business','entertainment','politics','sport','tech']

dataset = []#list of 2-uplet (article body,class)
for topic in folders:
    file_list = [f for f in listdir('data/bbc/'+topic) if f[0]!='.']
    #print(file_list)
    for filename in file_list:
        with open('data/bbc/'+topic+'/'+filename) as f:
            #print(topic,filename)
            contain = f.readlines()
            result = ''
            for elt in contain:
                if elt != '\n':
                    result+= elt[:-1]+' '
        dataset.append((result,topic))
#print(dataset[0])
</code></pre>

<pre><code class="language-python">import numpy as np, psutil
import datetime
import time
import fasttext
import json, collections
import string
import matplotlib.pyplot as plt
</code></pre>

<h1 id="part-i-batch-training-embedding-clustering">Part I :Batch training (embedding + clustering)</h1>

<p>In this part, we train a fasttext word embedding and a clustering of the given output vectors with the first x% of the dataset. The objective is to save these models (embedding + centroids) in order to use it for on the fly clustering in Part II.</p>

<h2 id="training-of-the-word-embedding">Training of the word embedding</h2>

<p>We extract bodies and classes and train x% of the first articles.</p>

<pre><code class="language-python">import random

x = 50#pourcentage for trainset

random.shuffle(dataset)

n = len(dataset)
n_train = int(x*n/100)
trainset = dataset[:n_train]
testset = dataset[n_train:]
n_test = len(testset)
print(len(trainset),'articles in the train over',n,'articles')#1769959

</code></pre>

<pre><code>1112 articles in the train over 2224 articles
</code></pre>

<p>We construct a csv file containing all the bodies of the train set, with option to lemmatize the corpus (al=vailable soon).</p>

<pre><code class="language-python">stop = n_train
cpt=0

outfile = 'corpus_bbc'+str(x)+'%'+'.csv'
f = open(outfile,'w')

for article in trainset:
    line = article[0]
    f.write(line+'\n')
    cpt+=1
print(outfile,'created with',cpt,'lines')
f.close()
</code></pre>

<pre><code>corpus_bbc50%.csv created with 1112 lines
</code></pre>

<h2 id="train-the-embedding-using-fasttext">Train the embedding using FastText</h2>

<p>We open the csv corpus file containing one body by line in UTF-8 format and train a FastText Cbow model. It takes 2 seconds for 1112 lines (50% of the entire dataset) in our 32-CPU servor.</p>

<pre><code class="language-python">%%time

corpusfile = outfile
#checking encoding UTF-8
#with open(corpusfile as f:
#    print(f)


# Skipgram model :
#model = fasttext.train_unsupervised(corpusfile, model='skipgram')

# or, cbow model :

d = 30
model = fasttext.train_unsupervised(corpusfile, model='cbow',dim=d)
model.save_model(&quot;model_&quot;+corpusfile+&quot;.bin&quot;)
</code></pre>

<pre><code>CPU times: user 21.9 s, sys: 336 ms, total: 22.2 s
Wall time: 2.13 s
</code></pre>

<h2 id="clustering-of-the-train-set">Clustering of the train set</h2>

<p>Here we vectorize each body of the train set in order to give to our clustering algorithm.</p>

<pre><code class="language-python">#generic function used for train AND on the fly test
#input : a body
#output : a vector (sum of vectors of each word of the body)
def vectorize(body):
    list_words =body.split()
    vect = np.zeros((1,d))
    for w in list_words:
        vect += model[w]
    return(vect)

with open(corpusfile) as f:
    list_vectors = [vectorize(line) for line in f]        # create a list of vectors representing bodies

train_vectors = np.array(list_vectors).reshape(n_train,-1)
</code></pre>

<p>We are ready to give this train vectors to our distclus library. We push these vectors in one batch and check the response of our Stremaing and MCMC algorithm.</p>

<p>WARNING: algo is running asynchronously and is still open after this block. It will be used again for on the fly analysis in Section 2.</p>

<h2 id="streaming-clustering">Streaming clustering</h2>

<p>Here we first give vectors of the trainset to our streaming algorithm. Articles are analyzed one by one. We ask for the number of clusters every 10 miliseconds.</p>

<pre><code class="language-python">from distclus import Streaming

#Streaming
algo = Streaming(mu=0.45, sigma=0.1, outRatio=2, outAfter=7)
print('Analyzing',n_train,'articles---')
algo.push(train_vectors[:1])
algo.run(rasync=True)
algo.push(train_vectors[1:])
for k in range(10):#monitoring during 10 seconds
    print(len(algo.centroids),'centers',end='|')
    time.sleep(0.01)
</code></pre>

<pre><code>Analyzing 1112 articles---
24 centers|24 centers|24 centers|24 centers|24 centers|24 centers|24 centers|24 centers|24 centers|24 centers|
</code></pre>

<h2 id="mcmc-algorithm-using-batch-decorator">MCMC algorithm (using Batch decorator)</h2>

<p>We also test our MCMC algorithm in a Batch mode. Batch object allows to perform a batch clustering using MCMC algorithm. You can play with parameters amp (the amplitude contsant in front of the temperature of the Gibbs measure) in order to add centers (the hotter it is, the more centers). You can also play with the number of centers to initialize the Markov chain, the maximum number of centers, and - of course - the number of iterations (all the vectors of the training set are used at each iterationin the batch mode).</p>

<pre><code class="language-python">from distclus import Batch, MCMC

print('Analyzing',n_train,'articles---')
algo = Batch(MCMC, init_k=5, b=1.,frame_size=n,amp=5,max_k = 10,mcmc_iter=5)
algo.run()
algo.push(train_vectors)
print(len(algo.centroids),'centers')
</code></pre>

<pre><code>Analyzing 1112 articles---
6 centers
</code></pre>

<h1 id="vizualization-of-the-clustering-of-the-train-set">Vizualization of the clustering of the train set</h1>

<p>We start a first analysis of the result. These few lines of code allow to generate a javascript visualisation of each cluster in your browser with bubbles and axes.
We first ask the label of each trained vectors.</p>

<pre><code class="language-python">labels=algo.predict(train_vectors)
</code></pre>

<p>We then count the size of each cluster.</p>

<pre><code class="language-python">def counts(centroids,labels):
    results = []
    for k in range(len(centroids)):
        cluster_i = np.where(labels==k)
        results.append(len(cluster_i[0]))
    return(results)

print(counts(algo.centroids,labels))
    
</code></pre>

<pre><code>[52, 156, 33, 208, 77, 196, 80, 34, 15, 17, 4, 48, 20, 7, 5, 27, 1, 43, 63, 19, 2, 2, 2, 1]
</code></pre>

<p>We construct a matrix to describe each cluster thanks to the topic (entertainment, politics, business, etc).</p>

<pre><code class="language-python">K = len(algo.centroids)
L = len(folders)
matrix_scores = np.zeros((K,L))

for i in range(K):
    current_topics = [x[1] for k,x in enumerate(trainset) if labels[k]==i]
    for j,topic in enumerate(folders):
        matrix_scores[i,j] = len([elt for elt in current_topics if elt==topic])/len([e for e in labels if e==i])
</code></pre>

<p>The following block generate an URL with the desired visualisation.</p>

<pre><code class="language-python">
from bubbles.drivers import MemDriver
from bubbles import Server
from random import randint
import requests


centers = matrix_scores.tolist()

result = {'centers': centers, 'counts': counts(algo.centroids,labels), 'columns': folders}

driver = MemDriver()
server = Server(driver)
port = randint(44001, 44999)
server.start(timeout=10, host='luzine.lumenai.fr', port=port, quiet=True)

result_id = driver.put_result(result)
print('http://luzine.lumenai.fr:{}/bubbles?result_id={}'.format(port, result_id))
</code></pre>

<pre><code>http://luzine.lumenai.fr:44768/bubbles?result_id=arznlpfzhgdazlrpzzdrngugeraumbop
</code></pre>

<h1 id="on-the-fly-analysis-of-a-test-dataset">On the fly analysis of a test dataset</h1>

<p>We are ready to analyze the test set sequentially in order to check the evolution of the dataset. We first select the size of the test set to give to the algorithm.</p>

<pre><code class="language-python">print('We start a real time clustering of',len(testset),'articles')
</code></pre>

<pre><code>We start a real time clustering of 1112 articles


WARNING:root:timeout reached, server was terminated
</code></pre>

<p>We then give one by one each article of the test set, proceed to the embedding thanks to the FastText model, and monitore the response of the online clustering algorithm after 100 milliseconds.</p>

<pre><code class="language-python">%%time
print('####')
print(len(algo.centroids),'centers at the beginning of the test xp')

test_vectors = []
new_date = []#list pf date with new center
past_K = len(algo.centroids)#number of centers at the present time
all_vectors = train_vectors

for i, elt in enumerate(testset):
    body = elt[0]
    new_vector = vectorize(body)
    all_vectors = np.append(all_vectors,new_vector,axis=0)
    current_label = algo.predict(new_vector)
    algo.push(new_vector)
    test_vectors.append(new_vector)
    time.sleep(0.03)
    labels = algo.predict(all_vectors)
    if len(algo.centroids)&lt;past_K:
        print('kill cluster for data',i,'with label',int(current_label))
    if len(algo.centroids)&gt;past_K:
        print('new center for data',i,'with label',int(current_label))
    else:
        pass
    past_K = len(algo.centroids)
print(len(algo.centroids),'centers at the end of the test xp')
</code></pre>

<pre><code>####
24 centers at the beginning of the test xp
24 centers at the end of the test xp
CPU times: user 17.5 s, sys: 948 ms, total: 18.4 s
Wall time: 43.8 s
</code></pre>

<h1 id="visualization-after-the-test-experience">Visualization after the test experience</h1>

<p>Here we propose to vizualize the resulting clustering (train +test analysis), where the size of the clusters are associated with the number of test data.</p>

<pre><code class="language-python">labels = algo.predict(all_vectors)


K = len(algo.centroids)

matrix_scores = np.zeros((K,5))

for i in range(K):
    if len([x for x in labels if x==i])&gt;0:
        current_topics = [x[1] for k,x in enumerate(dataset) if labels[k]==i]
        for j,topic in enumerate(folders):
            matrix_scores[i,j] = len([elt for elt in current_topics if elt==topic])/len([x for x in labels if x==i])
    else:
        matrix_scores[i,:] = np.zeros((1,5))

centers = matrix_scores.tolist()


result = {'centers': centers, 'counts': counts(algo.centroids,labels), 'columns': folders}

driver = MemDriver()
server = Server(driver)
port = randint(44001, 44999)
server.start(timeout=10, host='luzine.lumenai.fr', port=port, quiet=True)

result_id = driver.put_result(result)
print('http://luzine.lumenai.fr:{}/bubbles?result_id={}'.format(port, result_id))
</code></pre>

<pre><code>http://luzine.lumenai.fr:44620/bubbles?result_id=dkiuqwgxhgwouivzngeitbkgvknmrgku


WARNING:root:timeout reached, server was terminated
</code></pre>


    
    </div>
    </div>
</main>
  <footer></footer>


  <script src="/js/kube.js" type="text/javascript">
  </script>
  <script src="/js/kube.legenda.js" type="text/javascript">
  </script>
  <script src="/js/master.js" type="text/javascript">
  </script>
<script data-no-instant>document.write('<script src="/livereload.js?port=1313&mindelay=10"></' + 'script>')</script></body>

</html>
